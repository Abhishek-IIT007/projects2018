===================================== FILL YOUR EXPLANATION BELOW ===============================================================================
FOR THIS TASK I HAD TO REFER OPERATIONS ON WORD VECTOR ASSIGNMENT(WEEK 2 OF SEQUENCE MODELS: COURSERA)

CONCEPTS OF WORD EMBEDDINGS , WORD2VEC AND GloVe WORD VECTORS WAS USED.

I HAD TO USE THE PRETRAINED DATA SET 'glove.6B.50d.txt' FROM "https://nlp.stanford.edu/projects/glove/" WHICH HAD A 50 FEATURE VECTOR FOR EACH WORD

THEN MADE A FUNCTION loadGloveModel WHICH TOOK THE GLOVE FILE AND RETURNED A VARIABLE MODEL CONTAINING 400000 WORDS AND ITS VECTORS.REFERENCED FROM "http://ai.intelligentonlinetools.com/ml/convert-word-to-vector-glove-python/"

THEN IN THE creating_subclusters FUNCTION , I USED THE FEATURE VECTORS OF EACH WORDS IN A GIVEN TEXT FILE USING "model " DICT. THEN USED COSINE SIMILARITY TO GET SIMILAR WORDS.

EACH OF THE SIMILAR WORDS WERE WRITTEN IN THE OUTPUT FILE HAVING THE SAME NAME AS THE INPUT FILE. IN MY ODE I USED COSINE SIMILARITY TO BE  > 0.6 FOR WORDS TO BE SIMILAR.

DUE TO LACK OF TIME AND MY COMPUTER BEING RELATIVELY SLOW, I COULDN'T TRAIN ON 2 MILLION AVAILABLE WORDS.

SOME UNDEFINED WORDS LIKE "lsk" COULDN'T BE CLASSIFIED INTO GROUPS. 

 

